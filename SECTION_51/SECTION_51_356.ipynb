{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SECTION_51_356.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNytsMezA1sp3Ci08/5pHdX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pannhapat/udemy_datascience/blob/master/SECTION_51/SECTION_51_356.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QckWk_Qffhab",
        "colab_type": "text"
      },
      "source": [
        "**Extract the data from the csv**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTLh1wQcdQ69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "\n",
        "raw_csv_data = np.loadtxt('Audiobooks_data.csv',delimiter =',')\n",
        "unscaled_inputs_all = raw_csv_data[:,1:-1]\n",
        "targets_all = raw_csv_data[:,-1]\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRbYjpe_H2cD",
        "colab_type": "text"
      },
      "source": [
        "**Balance the dataset**\n",
        "I'll use the sklearn capabilities for standardizing the inputs\n",
        "\n",
        "Almost always we standardize all inputs\n",
        "10% gain for this problem\n",
        "\n",
        "1. We will count the number of targets that are 1s\n",
        "2. We will keep as many Os as 2s (we will delete the others)\n",
        "\n",
        "if we sum all the targets we will get the number of targets that are 1s\n",
        "\n",
        "if the target at position i is 0, and the number of zeroes is bigger than the number of 1s we want to take note of that index\n",
        "\n",
        "append() is a method appends(adds) an object to a list\n",
        "\n",
        "if the target at position i is 0 and the number of zeroes is bigger than the number of 1s, \n",
        "I'll know the indices of all data points to be removed\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkW_fo_hH1ar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_one_targets = int (np.sum(targets_all))\n",
        "zero_targets_counter = 0\n",
        "indices_to_remove = []\n",
        "\n",
        "for i in range (targets_all.shape[0]):\n",
        "    if targets_all[i] ==0:\n",
        "        zero_targets_counter +=1\n",
        "        if zero_targets_counter > num_one_targets:\n",
        "            indices_to_remove.append(i)\n",
        "\n",
        "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis = 0)\n",
        "targets_equals_priors = np.delete (targets_all, indices_to_remove, axis = 0)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwaVWhCJwEtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAGfg0N_TWnq",
        "colab_type": "text"
      },
      "source": [
        "**Standardiz the inputs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iu4dxQETZnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhRk18lETaiS",
        "colab_type": "text"
      },
      "source": [
        "# Shuffle the data\n",
        "That's the preprocessing library we imported from sklearn\n",
        "\n",
        "preprocessing.scale(X) is method that standardizes an array along an\n",
        "\n",
        "**Batching** \n",
        "We update the weights after each batch\n",
        "homogeneous\n",
        "Inside a batch the data is homogeneous, but between batches it is very heterogeneous\n",
        "\n",
        "We update the weights after each batch!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jIHW0OZgREN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
        "np.random.shuffle(shuffled_indices)\n",
        "\n",
        "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
        "shuffled_targets = targets_equals_priors[shuffled_indices]\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrnEgr_dgnRi",
        "colab_type": "text"
      },
      "source": [
        "**Split the dataset into train, validation, and test **\n",
        "np.arange([start],stop) is a method that returns a evenly spaced values within a given interval\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBPDRhTWgqrh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6aa670d7-e937-408b-8b7c-9b9aee455e17"
      },
      "source": [
        "samples_count = shuffled_inputs.shape[0]\n",
        "train_samples_count = int(0.8 * samples_count)\n",
        "validation_samples_count = int(0.1 * samples_count)\n",
        "test_samples_count = samples_count - train_samples_count - validation_samples_count\n",
        "\n",
        "train_inputs = shuffled_inputs[:train_samples_count]\n",
        "train_targets = shuffled_targets[:train_samples_count]\n",
        "\n",
        "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count+validation_samples_count]\n",
        "validation_targets = shuffled_targets[train_samples_count:train_samples_count+validation_samples_count]\n",
        "\n",
        "test_inputs = shuffled_inputs[train_samples_count+validation_samples_count:]\n",
        "test_targets = shuffled_targets[train_samples_count+validation_samples_count:]\n",
        "\n",
        "\n",
        "print(np.sum(train_targets),train_samples_count, np.sum(train_targets)/train_samples_count)\n",
        "print(np.sum(validation_targets),validation_samples_count, np.sum(validation_targets)/validation_samples_count)\n",
        "print(np.sum(test_targets),test_samples_count, np.sum(test_targets)/test_samples_count)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1798.0 3579 0.502374965074043\n",
            "219.0 447 0.4899328859060403\n",
            "220.0 448 0.49107142857142855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc4HBNxmgWPr",
        "colab_type": "text"
      },
      "source": [
        "Save the three datasets in *.npz\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6g6MizAgV2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prelMLEogaFa",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}